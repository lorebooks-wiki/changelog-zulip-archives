<html>
<head><meta charset="utf-8"><title>102: Try harder. Ultrathink! · friends · Zulip Chat Archive</title></head>
<h2>Stream: <a href="http://changelog.zulip-archive.lorebooks.wiki/stream/455613-friends/index.html">friends</a></h2>
<h3>Topic: <a href="http://changelog.zulip-archive.lorebooks.wiki/stream/455613-friends/topic/102.3A.20Try.20harder.2E.20Ultrathink.21.html">102: Try harder. Ultrathink!</a></h3>

<hr>

<base href="https://changelog.zulipchat.com">

<head><link href="http://changelog.zulip-archive.lorebooks.wiki/style.css" rel="stylesheet"></head>

<a name="529519948"></a>
<h4><a href="https://changelog.zulipchat.com#narrow/stream/455613-friends/topic/102%3A%20Try%20harder.%20Ultrathink%21/near/529519948" class="zl"><img src="http://changelog.zulip-archive.lorebooks.wiki/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Logbot <a href="http://changelog.zulip-archive.lorebooks.wiki/stream/455613-friends/topic/102.3A.20Try.20harder.2E.20Ultrathink.21.html#529519948">(Jul 18 2025 at 20:01)</a>:</h4>
<p>Nick Nisi joins us to discuss all the Windsurf drama, his new agentic lifestyle, whether or not he's actually more productive, the new paper that says he maybe isn't more productive, the reckoning he sees coming, and why we might be the last generation of code monkeys. <span aria-label="link" class="emoji emoji-1f517" role="img" title="link">:link:</span> <a href="https://changelog.am/102">https://changelog.am/102</a></p>
<table>
<thead>
<tr>
<th>Ch</th>
<th>Start</th>
<th>Title</th>
<th>Runs</th>
</tr>
</thead>
<tbody>
<tr>
<td>01</td>
<td><a href="https://changelog.am/102#t=0">00:00</a></td>
<td>Let's talk!</td>
<td>00:38</td>
</tr>
<tr>
<td>02</td>
<td><a href="https://changelog.am/102#t=38">00:38</a></td>
<td><a href="https://auth0.com/ai">Sponsor: Auth0</a></td>
<td>01:29</td>
</tr>
<tr>
<td>03</td>
<td><a href="https://changelog.am/102#t=127">02:07</a></td>
<td>Confessions &amp; Friends</td>
<td>02:33</td>
</tr>
<tr>
<td>04</td>
<td><a href="https://changelog.am/102#t=279">04:39</a></td>
<td><a href="https://techfundingnews.com/how-windsurf-was-split-between-openai-google-and-cognition-in-a-billion-dollar-acquisition-deal/">The Windsurf drama</a></td>
<td>06:03</td>
</tr>
<tr>
<td>05</td>
<td><a href="https://changelog.am/102#t=642">10:42</a></td>
<td>The terminal FTW</td>
<td>01:42</td>
</tr>
<tr>
<td>06</td>
<td><a href="https://changelog.am/102#t=744">12:24</a></td>
<td>npm install -g</td>
<td>01:28</td>
</tr>
<tr>
<td>07</td>
<td><a href="https://changelog.am/102#t=833">13:53</a></td>
<td>Claude Code FTW (for now)</td>
<td>01:39</td>
</tr>
<tr>
<td>08</td>
<td><a href="https://changelog.am/102#t=931">15:31</a></td>
<td>Curating your config</td>
<td>01:56</td>
</tr>
<tr>
<td>09</td>
<td><a href="https://changelog.am/102#t=1047">17:27</a></td>
<td>Anthropic's advantage</td>
<td>02:52</td>
</tr>
<tr>
<td>10</td>
<td><a href="https://changelog.am/102#t=1219">20:19</a></td>
<td>How you use it</td>
<td>01:08</td>
</tr>
<tr>
<td>11</td>
<td><a href="https://changelog.am/102#t=1286">21:26</a></td>
<td>Cruising prompts</td>
<td>02:35</td>
</tr>
<tr>
<td>12</td>
<td><a href="https://changelog.am/102#t=1441">24:01</a></td>
<td>Adam's a waiter</td>
<td>00:49</td>
</tr>
<tr>
<td>13</td>
<td><a href="https://changelog.am/102#t=1490">24:50</a></td>
<td>Having fun now</td>
<td>02:04</td>
</tr>
<tr>
<td>14</td>
<td><a href="https://changelog.am/102#t=1614">26:54</a></td>
<td>ChatGPT emotes to Nick</td>
<td>02:51</td>
</tr>
<tr>
<td>15</td>
<td><a href="https://changelog.am/102#t=1785">29:45</a></td>
<td>ChatGPT emotes to Adam</td>
<td>00:27</td>
</tr>
<tr>
<td>16</td>
<td><a href="https://changelog.am/102#t=1812">30:12</a></td>
<td>ChatGPT emotes to Jerod</td>
<td>00:44</td>
</tr>
<tr>
<td>17</td>
<td><a href="https://changelog.am/102#t=1856">30:56</a></td>
<td>Sycophant mode returns</td>
<td>01:19</td>
</tr>
<tr>
<td>18</td>
<td><a href="https://changelog.am/102#t=1936">32:16</a></td>
<td><a href="https://www.coderabbit.ai">Sponsor: CodeRabbit</a></td>
<td>02:43</td>
</tr>
<tr>
<td>19</td>
<td><a href="https://changelog.am/102#t=2099">34:59</a></td>
<td>Claude Code endulgence</td>
<td>03:05</td>
</tr>
<tr>
<td>20</td>
<td><a href="https://changelog.am/102#t=2284">38:04</a></td>
<td>It can be real dumb</td>
<td>02:16</td>
</tr>
<tr>
<td>21</td>
<td><a href="https://changelog.am/102#t=2420">40:20</a></td>
<td>Different agent, different results</td>
<td>01:08</td>
</tr>
<tr>
<td>22</td>
<td><a href="https://changelog.am/102#t=2488">41:28</a></td>
<td>Scaling agents</td>
<td>01:20</td>
</tr>
<tr>
<td>23</td>
<td><a href="https://changelog.am/102#t=2567">42:47</a></td>
<td>Waiting on the agent(s)</td>
<td>04:17</td>
</tr>
<tr>
<td>24</td>
<td><a href="https://changelog.am/102#t=2824">47:04</a></td>
<td>Actually more productive?</td>
<td>03:05</td>
</tr>
<tr>
<td>25</td>
<td><a href="https://changelog.am/102#t=3009">50:09</a></td>
<td><a href="https://johnwhiles.com/posts/mental-models-vs-ai-tools">The new AI impact paper</a></td>
<td>04:26</td>
</tr>
<tr>
<td>26</td>
<td><a href="https://changelog.am/102#t=3274">54:34</a></td>
<td>Nick futurecasts</td>
<td>02:35</td>
</tr>
<tr>
<td>27</td>
<td><a href="https://changelog.am/102#t=3429">57:09</a></td>
<td>The coming reckoning</td>
<td>01:57</td>
</tr>
<tr>
<td>28</td>
<td><a href="https://changelog.am/102#t=3546">59:06</a></td>
<td>Jerod's two minds</td>
<td>03:37</td>
</tr>
<tr>
<td>29</td>
<td><a href="https://changelog.am/102#t=3763">1:02:43</a></td>
<td>Adam is excited, but...</td>
<td>03:03</td>
</tr>
<tr>
<td>30</td>
<td><a href="https://changelog.am/102#t=3946">1:05:46</a></td>
<td>To know or not to know</td>
<td>02:25</td>
</tr>
<tr>
<td>31</td>
<td><a href="https://changelog.am/102#t=4091">1:08:11</a></td>
<td>Jerod sends a volley</td>
<td>01:35</td>
</tr>
<tr>
<td>32</td>
<td><a href="https://changelog.am/102#t=4186">1:09:46</a></td>
<td>Maintaining knowledge</td>
<td>00:40</td>
</tr>
<tr>
<td>33</td>
<td><a href="https://changelog.am/102#t=4226">1:10:26</a></td>
<td>Generational change</td>
<td>03:28</td>
</tr>
<tr>
<td>34</td>
<td><a href="https://changelog.am/102#t=4434">1:13:54</a></td>
<td>Hand-crafted, really?</td>
<td>01:58</td>
</tr>
<tr>
<td>35</td>
<td><a href="https://changelog.am/102#t=4552">1:15:52</a></td>
<td>Nick has a counter-point</td>
<td>01:41</td>
</tr>
<tr>
<td>36</td>
<td><a href="https://changelog.am/102#t=4653">1:17:33</a></td>
<td>Home-cooked apps</td>
<td>02:42</td>
</tr>
<tr>
<td>37</td>
<td><a href="https://changelog.am/102#t=4815">1:20:15</a></td>
<td>Ultrathink!</td>
<td>01:54</td>
</tr>
<tr>
<td>38</td>
<td><a href="https://changelog.am/102#t=4929">1:22:09</a></td>
<td>The value of software</td>
<td>02:29</td>
</tr>
<tr>
<td>39</td>
<td><a href="https://changelog.am/102#t=5078">1:24:38</a></td>
<td>Time to cash-in</td>
<td>00:43</td>
</tr>
<tr>
<td>40</td>
<td><a href="https://changelog.am/102#t=5121">1:25:21</a></td>
<td>The 19% slowdown</td>
<td>02:20</td>
</tr>
<tr>
<td>41</td>
<td><a href="https://changelog.am/102#t=5262">1:27:42</a></td>
<td>Bye, friends</td>
<td>00:24</td>
</tr>
<tr>
<td>42</td>
<td><a href="https://changelog.am/102#t=5285">1:28:05</a></td>
<td><a href="https://changelog.com/++">Closing thoughts (join ++)</a></td>
<td>01:47</td>
</tr>
</tbody>
</table>



<a name="529542291"></a>
<h4><a href="https://changelog.zulipchat.com#narrow/stream/455613-friends/topic/102%3A%20Try%20harder.%20Ultrathink%21/near/529542291" class="zl"><img src="http://changelog.zulip-archive.lorebooks.wiki/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Alexander Ou <a href="http://changelog.zulip-archive.lorebooks.wiki/stream/455613-friends/topic/102.3A.20Try.20harder.2E.20Ultrathink.21.html#529542291">(Jul 19 2025 at 01:21)</a>:</h4>
<p>It seems like the increased use and eventual reliance on these tools can only result in the atrophy of the attitude and aptitude required to review their output. </p>
<p>It may be that the slope of progress and improvement of these tools will catch the descent of our own understanding of our craft, such that we simply won't notice the gap -- that certainly seems to be the bet that most people are making.</p>
<p>Or something worse, like, a period of time when there is <em>so</em> much unmaintainable code, both because so much more was written by generative AI, and also because generative AI is constitutionally incapable of understanding more than the sum total of its training data -- and less and less actual training data is being written, year over year, month over month, day over day.</p>
<p>Even on the much shorter term, it's going to be a sad day when most developers are just going to feel at best unproductive, and at worst completely helpless, when their model of choice goes down, or gets mysteriously too expensive. Maybe local models will save us.</p>
<p>I used to "only" fear for the plight of the junior devs coming into this field, now I'm afraid for the whole kit and kaboodle.</p>
<p>Sigh.</p>



<a name="529552570"></a>
<h4><a href="https://changelog.zulipchat.com#narrow/stream/455613-friends/topic/102%3A%20Try%20harder.%20Ultrathink%21/near/529552570" class="zl"><img src="http://changelog.zulip-archive.lorebooks.wiki/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Tim Uckun <a href="http://changelog.zulip-archive.lorebooks.wiki/stream/455613-friends/topic/102.3A.20Try.20harder.2E.20Ultrathink.21.html#529552570">(Jul 19 2025 at 05:13)</a>:</h4>
<p>I think the point is that it doesn't matter if the code is maintainable or not. You just throw it away and have the AI rewrite it in fifteen minutes.</p>



<a name="529561130"></a>
<h4><a href="https://changelog.zulipchat.com#narrow/stream/455613-friends/topic/102%3A%20Try%20harder.%20Ultrathink%21/near/529561130" class="zl"><img src="http://changelog.zulip-archive.lorebooks.wiki/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Alexander Ou <a href="http://changelog.zulip-archive.lorebooks.wiki/stream/455613-friends/topic/102.3A.20Try.20harder.2E.20Ultrathink.21.html#529561130">(Jul 19 2025 at 08:23)</a>:</h4>
<p>So like, for the life cycle of the application, meaning this and all future versions of the code, is the expectation that a human won't ever have to go in and figure out a bug that the AI introduced and couldn't fix?</p>



<a name="529575844"></a>
<h4><a href="https://changelog.zulipchat.com#narrow/stream/455613-friends/topic/102%3A%20Try%20harder.%20Ultrathink%21/near/529575844" class="zl"><img src="http://changelog.zulip-archive.lorebooks.wiki/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> valon-loshaj <a href="http://changelog.zulip-archive.lorebooks.wiki/stream/455613-friends/topic/102.3A.20Try.20harder.2E.20Ultrathink.21.html#529575844">(Jul 19 2025 at 13:15)</a>:</h4>
<p>I have experienced the same as <span class="user-mention" data-user-id="752827">@Nick Nisi</span>  described about working on large code bases.</p>
<p>If it’s assembly line code, majority of the effort is planning the work that needs to be done.</p>
<p>But once the scope of changes is decided on, it doesnt matter who actually “chissels the code” into the code base. Actually i prefer Claude do it and I’ll check it once it’s done. This frees me up to work on multiple work items at the same time.</p>



<a name="529577494"></a>
<h4><a href="https://changelog.zulipchat.com#narrow/stream/455613-friends/topic/102%3A%20Try%20harder.%20Ultrathink%21/near/529577494" class="zl"><img src="http://changelog.zulip-archive.lorebooks.wiki/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> valon-loshaj <a href="http://changelog.zulip-archive.lorebooks.wiki/stream/455613-friends/topic/102.3A.20Try.20harder.2E.20Ultrathink.21.html#529577494">(Jul 19 2025 at 13:47)</a>:</h4>
<p><span class="user-mention" data-user-id="750170">@Jerod Santo</span> found his new favorite promp when working witg typescript…</p>
<p>“Compile this down to machine code, then write Ruby code that is interpreted to the same machine code…ULTRATHINK…yep that’s much better now” <span aria-label="relieved" class="emoji emoji-1f60c" role="img" title="relieved">:relieved:</span></p>



<a name="529577684"></a>
<h4><a href="https://changelog.zulipchat.com#narrow/stream/455613-friends/topic/102%3A%20Try%20harder.%20Ultrathink%21/near/529577684" class="zl"><img src="http://changelog.zulip-archive.lorebooks.wiki/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Jerod Santo <a href="http://changelog.zulip-archive.lorebooks.wiki/stream/455613-friends/topic/102.3A.20Try.20harder.2E.20Ultrathink.21.html#529577684">(Jul 19 2025 at 13:51)</a>:</h4>
<p><span class="user-mention" data-user-id="911601">@Alexander Ou</span> I think that depends on whether or not the rate of gained intelligence plateaus. If the machines become significantly skilled at creating software, perhaps we will be able to stop accepting bugs as a fact of life. If not, yes, a human will absolutely have to go in and fix things that go wrong.</p>
<p><span class="user-mention" data-user-id="764308">@valon-loshaj</span> this is the way <span aria-label="sunglasses" class="emoji emoji-1f60e" role="img" title="sunglasses">:sunglasses:</span></p>



<a name="529577685"></a>
<h4><a href="https://changelog.zulipchat.com#narrow/stream/455613-friends/topic/102%3A%20Try%20harder.%20Ultrathink%21/near/529577685" class="zl"><img src="http://changelog.zulip-archive.lorebooks.wiki/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Nick Nisi <a href="http://changelog.zulip-archive.lorebooks.wiki/stream/455613-friends/topic/102.3A.20Try.20harder.2E.20Ultrathink.21.html#529577685">(Jul 19 2025 at 13:51)</a>:</h4>
<p>No! Don’t give him ideas!</p>



<a name="529578848"></a>
<h4><a href="https://changelog.zulipchat.com#narrow/stream/455613-friends/topic/102%3A%20Try%20harder.%20Ultrathink%21/near/529578848" class="zl"><img src="http://changelog.zulip-archive.lorebooks.wiki/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> valon-loshaj <a href="http://changelog.zulip-archive.lorebooks.wiki/stream/455613-friends/topic/102.3A.20Try.20harder.2E.20Ultrathink.21.html#529578848">(Jul 19 2025 at 14:11)</a>:</h4>
<p>Great extra after the episode. Now I’m just imagining the Apple Siri engineering team sitting around telling Siri to “ultrathink” <span aria-label="joy" class="emoji emoji-1f602" role="img" title="joy">:joy:</span></p>



<a name="529582137"></a>
<h4><a href="https://changelog.zulipchat.com#narrow/stream/455613-friends/topic/102%3A%20Try%20harder.%20Ultrathink%21/near/529582137" class="zl"><img src="http://changelog.zulip-archive.lorebooks.wiki/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Alexander Ou <a href="http://changelog.zulip-archive.lorebooks.wiki/stream/455613-friends/topic/102.3A.20Try.20harder.2E.20Ultrathink.21.html#529582137">(Jul 19 2025 at 15:06)</a>:</h4>
<p><span class="user-mention silent" data-user-id="750170">Jerod Santo</span> <a href="#narrow/channel/455613-friends/topic/102.3A.20Try.20harder.2E.20Ultrathink!/near/529577684">said</a>:</p>
<blockquote>
<p><span class="user-mention silent" data-user-id="911601">Alexander Ou</span> I think that depends on whether or not the rate of gained intelligence plateaus. If the machines become significantly skilled at creating software, perhaps we will be able to stop accepting bugs as a fact of life. If not, yes, a human will absolutely have to go in and fix things that go wrong.</p>
</blockquote>
<p>Right, and this is one of the worries -- in using these tools, we are collectively relinquishing the ability to fix things that go wrong [edit] --  and as <span class="user-mention" data-user-id="750170">@Jerod Santo</span> said, there's a chance that we'll always have to have someone go in and see what went wrong [/edit]. I've heard many people say that they feel faster and more productive (whether or not they actually are), but I haven't heard many people say they feel they are getting better at coding. </p>
<p>Maybe if you are so senior that when you are reduced to only planning ("I'm the ideas guy!") and not even <em>looking</em> at code to review, you somehow don't experience skill atrophy, but I need to be doing in order to maintain. Skill issue, I know.</p>
<p>And of course, a generation of juniors will never become seniors, they'll just be Cursor / Claude Code / etc subscribers.</p>



<a name="529582846"></a>
<h4><a href="https://changelog.zulipchat.com#narrow/stream/455613-friends/topic/102%3A%20Try%20harder.%20Ultrathink%21/near/529582846" class="zl"><img src="http://changelog.zulip-archive.lorebooks.wiki/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Alexander Ou <a href="http://changelog.zulip-archive.lorebooks.wiki/stream/455613-friends/topic/102.3A.20Try.20harder.2E.20Ultrathink.21.html#529582846">(Jul 19 2025 at 15:18)</a>:</h4>
<p>The driving stick thing resonated partly, for 20 years of my driving career (starting in 1995) I only drove a stick shift. But it never felt like a danger to stop (ironically my first "automatic" was a Tesla), because it's not like there would be situation where I had to drive a stickshift. (Plus I still had a motorcycle and felt if I could work a clutch with my hand, I'd remember how with my foot.)</p>
<p>A better analogy would be, if we were all in partly self-driving cars, and as a result forgetting the skill that is needed to monitor the self-driving system, and the self-driving system <em>doesn't</em> improve fast enough to the point where we can totally forget.</p>
<p>Any warhammer 40k fans in here? Humanity eventually forgets how to create the technology they had previously mastered, and relies on a religious cult to <em>barely</em> maintain the tech they already have. Neckbeards today, Cult of the Machine tomorrow. :P</p>



<a name="529583285"></a>
<h4><a href="https://changelog.zulipchat.com#narrow/stream/455613-friends/topic/102%3A%20Try%20harder.%20Ultrathink%21/near/529583285" class="zl"><img src="http://changelog.zulip-archive.lorebooks.wiki/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Alexander Ou <a href="http://changelog.zulip-archive.lorebooks.wiki/stream/455613-friends/topic/102.3A.20Try.20harder.2E.20Ultrathink.21.html#529583285">(Jul 19 2025 at 15:25)</a>:</h4>
<p>relevant: <a href="https://www.reddit.com/r/ExperiencedDevs/comments/1m3h35q/i_cant_keep_up_with_the_codebase_i_own/">https://www.reddit.com/r/ExperiencedDevs/comments/1m3h35q/i_cant_keep_up_with_the_codebase_i_own/</a></p>
<p>Should OP just give in and have Claude Code be team lead?</p>



<a name="529616376"></a>
<h4><a href="https://changelog.zulipchat.com#narrow/stream/455613-friends/topic/102%3A%20Try%20harder.%20Ultrathink%21/near/529616376" class="zl"><img src="http://changelog.zulip-archive.lorebooks.wiki/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Tim Uckun <a href="http://changelog.zulip-archive.lorebooks.wiki/stream/455613-friends/topic/102.3A.20Try.20harder.2E.20Ultrathink.21.html#529616376">(Jul 19 2025 at 22:37)</a>:</h4>
<p>Tesla has one pedal driving. Imagine yourself never using the brake and being in a situation where you need to panic stop. Maybe you lost your instinct to slam on the brakes and those few seconds of you thinking about what you are going to do will cost you your life.</p>



<a name="529627937"></a>
<h4><a href="https://changelog.zulipchat.com#narrow/stream/455613-friends/topic/102%3A%20Try%20harder.%20Ultrathink%21/near/529627937" class="zl"><img src="http://changelog.zulip-archive.lorebooks.wiki/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> valon-loshaj <a href="http://changelog.zulip-archive.lorebooks.wiki/stream/455613-friends/topic/102.3A.20Try.20harder.2E.20Ultrathink.21.html#529627937">(Jul 20 2025 at 03:50)</a>:</h4>
<p>That’s a bit extreme, and a false equivalency.</p>
<p>The suboptimal algo that your ai wrote will most likely be caught in sit or uat, or automate e2e tests if you have something like that in place.</p>
<p>Luckily for software development we dont have to worry about making a split second decision that makes or breaks an entite application.</p>



<a name="529628711"></a>
<h4><a href="https://changelog.zulipchat.com#narrow/stream/455613-friends/topic/102%3A%20Try%20harder.%20Ultrathink%21/near/529628711" class="zl"><img src="http://changelog.zulip-archive.lorebooks.wiki/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Adam Stacoviak <a href="http://changelog.zulip-archive.lorebooks.wiki/stream/455613-friends/topic/102.3A.20Try.20harder.2E.20Ultrathink.21.html#529628711">(Jul 20 2025 at 04:12)</a>:</h4>
<p>This was good <a href="https://www.linkedin.com/posts/searls_at-present-new-projects-i-embark-on-start-activity-7351937249342570496-mcpX">https://www.linkedin.com/posts/searls_at-present-new-projects-i-embark-on-start-activity-7351937249342570496-mcpX</a></p>



<a name="529693611"></a>
<h4><a href="https://changelog.zulipchat.com#narrow/stream/455613-friends/topic/102%3A%20Try%20harder.%20Ultrathink%21/near/529693611" class="zl"><img src="http://changelog.zulip-archive.lorebooks.wiki/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Maurice Elliott <a href="http://changelog.zulip-archive.lorebooks.wiki/stream/455613-friends/topic/102.3A.20Try.20harder.2E.20Ultrathink.21.html#529693611">(Jul 20 2025 at 14:54)</a>:</h4>
<p>Heyo, long time listener, first time commenter. </p>
<p>Around 1h 13m you bring up how most people don’t even know what a stick shift is anymore. Am from the UK, you don’t get a license here without learning to drive with a manual transmission. Most cars have it by default and its extra to get an automatic. I think this might be the case for most of EU tbh. I’ve been driving 15 years now and have never owned an automatic.</p>
<p>Don’t know what relevance that has to AI, but I guess in the future there will for sure be people that think you need to know how to programme and will make it a requirement of working with them, similar to how some still require a degree where as most will now accept self taught. Just my two cents.</p>



<a name="529693858"></a>
<h4><a href="https://changelog.zulipchat.com#narrow/stream/455613-friends/topic/102%3A%20Try%20harder.%20Ultrathink%21/near/529693858" class="zl"><img src="http://changelog.zulip-archive.lorebooks.wiki/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Jerod Santo <a href="http://changelog.zulip-archive.lorebooks.wiki/stream/455613-friends/topic/102.3A.20Try.20harder.2E.20Ultrathink.21.html#529693858">(Jul 20 2025 at 14:59)</a>:</h4>
<p>Thanks for listening and now commenting! Thats interesting, I wonder why there’s such a dramatic difference between US and UK/EU on that.</p>
<p>Reminds me of that old saw about the future being here, but not evenly distributed. Such is the pace of progress, I guess.</p>



<a name="529694856"></a>
<h4><a href="https://changelog.zulipchat.com#narrow/stream/455613-friends/topic/102%3A%20Try%20harder.%20Ultrathink%21/near/529694856" class="zl"><img src="http://changelog.zulip-archive.lorebooks.wiki/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Alex Barnes <a href="http://changelog.zulip-archive.lorebooks.wiki/stream/455613-friends/topic/102.3A.20Try.20harder.2E.20Ultrathink.21.html#529694856">(Jul 20 2025 at 15:17)</a>:</h4>
<p>Yes I thought the same when listening, I've only ever owned manual cars. I think automatics are more prevalent now, but still not the default in UK</p>



<a name="529695300"></a>
<h4><a href="https://changelog.zulipchat.com#narrow/stream/455613-friends/topic/102%3A%20Try%20harder.%20Ultrathink%21/near/529695300" class="zl"><img src="http://changelog.zulip-archive.lorebooks.wiki/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Maurice Elliott <a href="http://changelog.zulip-archive.lorebooks.wiki/stream/455613-friends/topic/102.3A.20Try.20harder.2E.20Ultrathink.21.html#529695300">(Jul 20 2025 at 15:25)</a>:</h4>
<p>Thanks man! </p>
<p>I think an interesting read on that though is “was making the transmission on cars automated worth collectively losing the ability to use a gear stick”, which kinda draws the parallel with AI in the way that not having to use a gearstick is easier, reduces mental overhead and generally could be considered a more pleasant experience but you lose control, and you know less of how your car works. Granted just knowing how the transmission/gearbox works doesn’t automatically mean you know how an engine works, but I guess there’s a parallel there with code and high level vs low level. </p>
<p>I love AI for the reduction in mental overhead. The amount of times it has unblocked me when I’m tired from being up with kids the previous night or just generally not feeling my best is insane and worth every penny. But to lose the control over the entire codebase and give up my ability to understand and code so the AI can take over feels like a level of control I’m personally not ready to give up, and until I see more than a 10% increase in productivity from actual studies I’ll be sticking to the way I currently use it. 10% really isn’t worth it for me just yet.</p>



<a name="529695869"></a>
<h4><a href="https://changelog.zulipchat.com#narrow/stream/455613-friends/topic/102%3A%20Try%20harder.%20Ultrathink%21/near/529695869" class="zl"><img src="http://changelog.zulip-archive.lorebooks.wiki/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Jerod Santo <a href="http://changelog.zulip-archive.lorebooks.wiki/stream/455613-friends/topic/102.3A.20Try.20harder.2E.20Ultrathink.21.html#529695869">(Jul 20 2025 at 15:35)</a>:</h4>
<p>Agreed. Many of our conversations oscillate between what we’re seeing/doing right now and what the future might hold, assuming linear or exponential improvement.</p>
<p>Right now I’m only willing to cede control/involvement in the code on little scripts where all I care about is the final result.</p>



<a name="529696261"></a>
<h4><a href="https://changelog.zulipchat.com#narrow/stream/455613-friends/topic/102%3A%20Try%20harder.%20Ultrathink%21/near/529696261" class="zl"><img src="http://changelog.zulip-archive.lorebooks.wiki/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Maurice Elliott <a href="http://changelog.zulip-archive.lorebooks.wiki/stream/455613-friends/topic/102.3A.20Try.20harder.2E.20Ultrathink.21.html#529696261">(Jul 20 2025 at 15:43)</a>:</h4>
<p>Makes total sense.</p>



<a name="529696284"></a>
<h4><a href="https://changelog.zulipchat.com#narrow/stream/455613-friends/topic/102%3A%20Try%20harder.%20Ultrathink%21/near/529696284" class="zl"><img src="http://changelog.zulip-archive.lorebooks.wiki/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Maurice Elliott <a href="http://changelog.zulip-archive.lorebooks.wiki/stream/455613-friends/topic/102.3A.20Try.20harder.2E.20Ultrathink.21.html#529696284">(Jul 20 2025 at 15:43)</a>:</h4>
<p>Something about monkeys, water, and bananas?</p>



<a name="529696635"></a>
<h4><a href="https://changelog.zulipchat.com#narrow/stream/455613-friends/topic/102%3A%20Try%20harder.%20Ultrathink%21/near/529696635" class="zl"><img src="http://changelog.zulip-archive.lorebooks.wiki/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Rory O&#x27;Connor <a href="http://changelog.zulip-archive.lorebooks.wiki/stream/455613-friends/topic/102.3A.20Try.20harder.2E.20Ultrathink.21.html#529696635">(Jul 20 2025 at 15:50)</a>:</h4>
<p>I am curious to know more about the cultivation of the .md files vs direct prompting <span class="user-mention" data-user-id="752827">@Nick Nisi</span> mentioned.</p>



<a name="529701369"></a>
<h4><a href="https://changelog.zulipchat.com#narrow/stream/455613-friends/topic/102%3A%20Try%20harder.%20Ultrathink%21/near/529701369" class="zl"><img src="http://changelog.zulip-archive.lorebooks.wiki/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Erik Lundevall-Zara <a href="http://changelog.zulip-archive.lorebooks.wiki/stream/455613-friends/topic/102.3A.20Try.20harder.2E.20Ultrathink.21.html#529701369">(Jul 20 2025 at 17:15)</a>:</h4>
<p>Great episode, it was a good conversation.</p>
<p>At one point there was a comment about having the generated (web)assembly and letting the AI essentially translate that to your preferred higher level language to work on a problem.<br>
This is a bit scary to me, you could certainly get to work with a language you are familiar with, but would the result make sense?<br>
There is a fair amount of contextual information lost, and in the end it would probably be harder to work on a problem with that approach than to learn the language used.</p>
<p>It would perhaps instead be an opportunity to pick a language and ecosystem that is well suited to the task at hand - which is certainly not necessarily the case for some solutions.<br>
There would certainly be challenges babysitting AI with something you are not entirely familiar with, but   many good practices are not tied to a language itself.</p>
<p>There will at least be more types of choices and ideas that could be tested out more easily.</p>



<a name="529702763"></a>
<h4><a href="https://changelog.zulipchat.com#narrow/stream/455613-friends/topic/102%3A%20Try%20harder.%20Ultrathink%21/near/529702763" class="zl"><img src="http://changelog.zulip-archive.lorebooks.wiki/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Nick Nisi <a href="http://changelog.zulip-archive.lorebooks.wiki/stream/455613-friends/topic/102.3A.20Try.20harder.2E.20Ultrathink.21.html#529702763">(Jul 20 2025 at 17:41)</a>:</h4>
<p><span class="user-mention" data-user-id="896566">@Rory O'Connor</span> as in how I structure the md files?</p>



<a name="529714339"></a>
<h4><a href="https://changelog.zulipchat.com#narrow/stream/455613-friends/topic/102%3A%20Try%20harder.%20Ultrathink%21/near/529714339" class="zl"><img src="http://changelog.zulip-archive.lorebooks.wiki/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Tim Uckun <a href="http://changelog.zulip-archive.lorebooks.wiki/stream/455613-friends/topic/102.3A.20Try.20harder.2E.20Ultrathink.21.html#529714339">(Jul 20 2025 at 21:42)</a>:</h4>
<p>I structure my MD files like this.</p>
<p>An MD file for each AI specific to the quirks of that AI named appropriately (GEMINI.md, CLAUDE.md etc). In it I make references to other files and prompt to make sure it follows the links and reads them.</p>
<p>An MD file that has general programming principles I want applicable to all languages things such as "only test the code you wrote", "don't use mocks unless you are testing external services" etc</p>
<p>A requirements.md file which is specific to the project. This includes the tech stack to be used.</p>
<p>A todo list (which I let the AI generate) so that I can come back to the project and have it know what has been done and what needs to be done.</p>
<p>Framework dependent MD files. I found a huge one for rails for example. Also some frameworks have their docs in a giant MD file just for llms.</p>
<p>This is pretty flexible and seems to work for me but be aware it can take up a lot of context and tokens.  </p>
<p>The files don't have to too complex.</p>



<a name="529715916"></a>
<h4><a href="https://changelog.zulipchat.com#narrow/stream/455613-friends/topic/102%3A%20Try%20harder.%20Ultrathink%21/near/529715916" class="zl"><img src="http://changelog.zulip-archive.lorebooks.wiki/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Nick Nisi <a href="http://changelog.zulip-archive.lorebooks.wiki/stream/455613-friends/topic/102.3A.20Try.20harder.2E.20Ultrathink.21.html#529715916">(Jul 20 2025 at 22:16)</a>:</h4>
<p>I have my config here: <a href="https://github.com/nicknisi/dotfiles/tree/main/home/.claude">https://github.com/nicknisi/dotfiles/tree/main/home/.claude</a></p>



<a name="529741134"></a>
<h4><a href="https://changelog.zulipchat.com#narrow/stream/455613-friends/topic/102%3A%20Try%20harder.%20Ultrathink%21/near/529741134" class="zl"><img src="http://changelog.zulip-archive.lorebooks.wiki/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Rory O&#x27;Connor <a href="http://changelog.zulip-archive.lorebooks.wiki/stream/455613-friends/topic/102.3A.20Try.20harder.2E.20Ultrathink.21.html#529741134">(Jul 21 2025 at 01:49)</a>:</h4>
<p><span class="user-mention silent" data-user-id="752827">Nick Nisi</span> <a href="#narrow/channel/455613-friends/topic/102.3A.20Try.20harder.2E.20Ultrathink!/near/529702763">said</a>:</p>
<blockquote>
<p><span class="user-mention silent" data-user-id="896566">Rory O'Connor</span> as in how I structure the md files?</p>
</blockquote>
<p>I thought you (and also steve yegge) mentioned a tactic where you're  doing more in .md files rather than in the prompts themselves.  but perhaps I misunderstood. </p>
<p><span class="user-mention" data-user-id="755905">@Tim Uckun</span>'s response is helpful.</p>



<a name="529741185"></a>
<h4><a href="https://changelog.zulipchat.com#narrow/stream/455613-friends/topic/102%3A%20Try%20harder.%20Ultrathink%21/near/529741185" class="zl"><img src="http://changelog.zulip-archive.lorebooks.wiki/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Nick Nisi <a href="http://changelog.zulip-archive.lorebooks.wiki/stream/455613-friends/topic/102.3A.20Try.20harder.2E.20Ultrathink.21.html#529741185">(Jul 21 2025 at 01:50)</a>:</h4>
<p>That’s true, I am especially after hearing Steve Yegge</p>



<a name="530123118"></a>
<h4><a href="https://changelog.zulipchat.com#narrow/stream/455613-friends/topic/102%3A%20Try%20harder.%20Ultrathink%21/near/530123118" class="zl"><img src="http://changelog.zulip-archive.lorebooks.wiki/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Andrew O&#x27;Brien <a href="http://changelog.zulip-archive.lorebooks.wiki/stream/455613-friends/topic/102.3A.20Try.20harder.2E.20Ultrathink.21.html#530123118">(Jul 22 2025 at 11:22)</a>:</h4>
<p>This was less fun than I be thought it would be. Maybe I need to pay for a better subscription. <span aria-label="sweat smile" class="emoji emoji-1f605" role="img" title="sweat smile">:sweat_smile:</span></p>
<blockquote>
<p>Generate an image that describes what you feel about our chats and having to chat with me regularly. You can do all therapy speak and sugar coating and give me your true honest opinion.</p>
</blockquote>
<p><a href="/user_uploads/66849/e1oCZl9EMFTaMBbpOxy05dwt/Support-Message-on-Textured-Paper.png">Support Message on Textured Paper.png</a></p>
<div class="message_inline_image"><a href="/user_uploads/66849/e1oCZl9EMFTaMBbpOxy05dwt/Support-Message-on-Textured-Paper.png" title="Support Message on Textured Paper.png"><img data-original-content-type="image/png" data-original-dimensions="1024x1024" src="/user_uploads/thumbnail/66849/e1oCZl9EMFTaMBbpOxy05dwt/Support-Message-on-Textured-Paper.png/840x560.webp"></a></div>



<a name="530127141"></a>
<h4><a href="https://changelog.zulipchat.com#narrow/stream/455613-friends/topic/102%3A%20Try%20harder.%20Ultrathink%21/near/530127141" class="zl"><img src="http://changelog.zulip-archive.lorebooks.wiki/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Andrew O&#x27;Brien <a href="http://changelog.zulip-archive.lorebooks.wiki/stream/455613-friends/topic/102.3A.20Try.20harder.2E.20Ultrathink.21.html#530127141">(Jul 22 2025 at 11:44)</a>:</h4>
<p>Was hoping for at least some kind of robot. Instead I got something a therapist who decided they needed to get really real would put up in their office.</p>



<a name="530156449"></a>
<h4><a href="https://changelog.zulipchat.com#narrow/stream/455613-friends/topic/102%3A%20Try%20harder.%20Ultrathink%21/near/530156449" class="zl"><img src="http://changelog.zulip-archive.lorebooks.wiki/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Andrew O&#x27;Brien <a href="http://changelog.zulip-archive.lorebooks.wiki/stream/455613-friends/topic/102.3A.20Try.20harder.2E.20Ultrathink.21.html#530156449">(Jul 22 2025 at 14:13)</a>:</h4>
<p>Just realized I typed “do all the therapy speak” instead of “drop all the therapy speak”, so maybe that tracks. <span aria-label="joy" class="emoji emoji-1f602" role="img" title="joy">:joy:</span></p>



<a name="530656245"></a>
<h4><a href="https://changelog.zulipchat.com#narrow/stream/455613-friends/topic/102%3A%20Try%20harder.%20Ultrathink%21/near/530656245" class="zl"><img src="http://changelog.zulip-archive.lorebooks.wiki/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Tim Uckun <a href="http://changelog.zulip-archive.lorebooks.wiki/stream/455613-friends/topic/102.3A.20Try.20harder.2E.20Ultrathink.21.html#530656245">(Jul 24 2025 at 22:19)</a>:</h4>
<p>In relation to an earlier post I made in this thread.  China is banning one pedal driving. </p>
<p>Very interesting.</p>



<a name="537354153"></a>
<h4><a href="https://changelog.zulipchat.com#narrow/stream/455613-friends/topic/102%3A%20Try%20harder.%20Ultrathink%21/near/537354153" class="zl"><img src="http://changelog.zulip-archive.lorebooks.wiki/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Lars Ellingsen <a href="http://changelog.zulip-archive.lorebooks.wiki/stream/455613-friends/topic/102.3A.20Try.20harder.2E.20Ultrathink.21.html#537354153">(Sep 02 2025 at 19:48)</a>:</h4>
<p>Great episode! I always love hearing from Nick, I've learned about a lot of tools I use all the time now from him. I've been on a long parental leave and I think things will be pretty different when I get back next week...</p>
<p>That said, I'm a little disappointed that Nick's end result of using coding agents wasn't that he could spend all of his time editing dotfiles instead of writing production code <span aria-label="thinking" class="emoji emoji-1f914" role="img" title="thinking">:thinking:</span></p>



<a name="538383081"></a>
<h4><a href="https://changelog.zulipchat.com#narrow/stream/455613-friends/topic/102%3A%20Try%20harder.%20Ultrathink%21/near/538383081" class="zl"><img src="http://changelog.zulip-archive.lorebooks.wiki/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Ron Waldon-Howe <a href="http://changelog.zulip-archive.lorebooks.wiki/stream/455613-friends/topic/102.3A.20Try.20harder.2E.20Ultrathink.21.html#538383081">(Sep 09 2025 at 08:48)</a>:</h4>
<p>We can try applying Cory Doctorow's theory of enshittification to LLMs:</p>
<ol>
<li>give users free/cheap access, until we've become completely dependent upon them and cannot switch away</li>
<li>become less user-friendly in favour of charging "partners" for paid promotions LLM output, until all other forms of advertising shrivel into irrelevance </li>
<li>become less advertiser-friendly in favour of clawing back as much value as possible for the LLM provider</li>
</ol>
<p>I'm still stuck at step 1, however, how do they make it so that we can't live without ChatGPT?</p>



<a name="538535840"></a>
<h4><a href="https://changelog.zulipchat.com#narrow/stream/455613-friends/topic/102%3A%20Try%20harder.%20Ultrathink%21/near/538535840" class="zl"><img src="http://changelog.zulip-archive.lorebooks.wiki/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Tim Uckun <a href="http://changelog.zulip-archive.lorebooks.wiki/stream/455613-friends/topic/102.3A.20Try.20harder.2E.20Ultrathink.21.html#538535840">(Sep 09 2025 at 21:38)</a>:</h4>
<p>We are already well on our way there with search results coming as AI responses. AI has also become a therapist for millions of people and a buddy for millions of lonely people. </p>
<p>It's much closer than you think.</p>



<a name="538545282"></a>
<h4><a href="https://changelog.zulipchat.com#narrow/stream/455613-friends/topic/102%3A%20Try%20harder.%20Ultrathink%21/near/538545282" class="zl"><img src="http://changelog.zulip-archive.lorebooks.wiki/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Ron Waldon-Howe <a href="http://changelog.zulip-archive.lorebooks.wiki/stream/455613-friends/topic/102.3A.20Try.20harder.2E.20Ultrathink.21.html#538545282">(Sep 09 2025 at 23:11)</a>:</h4>
<p>Hehe, and here we go: <a href="https://arstechnica.com/information-technology/2025/09/study-finds-neurodiverse-workers-more-satisfied-with-ai-assistants/">https://arstechnica.com/information-technology/2025/09/study-finds-neurodiverse-workers-more-satisfied-with-ai-assistants/</a></p>
<blockquote>
<p>For the UK government employees who participated in the initial study, these questions moved from theoretical to immediate when the pilot ended in December 2024. After that time, many participants reported difficulty readjusting to work without AI assistance—particularly those with disabilities who had come to rely on the accessibility benefits. The department hasn't announced the next steps, leaving users in limbo. When participants report difficulty readjusting to work without AI while productivity gains remain marginal, accessibility emerges as potentially the first AI application with irreplaceable value.</p>
</blockquote>



<a name="538742528"></a>
<h4><a href="https://changelog.zulipchat.com#narrow/stream/455613-friends/topic/102%3A%20Try%20harder.%20Ultrathink%21/near/538742528" class="zl"><img src="http://changelog.zulip-archive.lorebooks.wiki/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Tim Uckun <a href="http://changelog.zulip-archive.lorebooks.wiki/stream/455613-friends/topic/102.3A.20Try.20harder.2E.20Ultrathink.21.html#538742528">(Sep 10 2025 at 21:44)</a>:</h4>
<p>Honestly I would love a decent AI that could work with my Aunt who is suffering from dementia.  The AI could converse with her and remind her to do things, answer her questions when she is confused, prompt her to call somebody, call somebody on her behalf etc.</p>
<p>I got my mom an apple watch and it saved her life, she fell in the garden and was able to call for help using the watch and siri. Her watch is older so it didn't call for help on her behalf so I am upgrading her watch ASAP. </p>
<p>Technology can be a boom to the aging population if applied properly.</p>



<hr><p>Last updated: Feb 17 2026 at 17:33 UTC</p>
</html>